{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#importing keras libraries\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Dense, Activation ,Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "#importing sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory path for full dataset\n",
    "imagedir =\"/home/sanjeev/DL_POC/MlaImg_Data/Malimg_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tFamily:       Adialer.C\tNumber of images: 122\n",
      "Label: 1\tFamily:       Agent.FYI\tNumber of images: 116\n",
      "Label: 2\tFamily:       Allaple.A\tNumber of images: 2949\n",
      "Label: 3\tFamily:       Allaple.L\tNumber of images: 1591\n",
      "Label: 4\tFamily:   Alueron.gen!J\tNumber of images: 198\n",
      "Label: 5\tFamily:       Autorun.K\tNumber of images: 106\n",
      "Label: 6\tFamily:     C2LOP.gen!g\tNumber of images: 200\n",
      "Label: 7\tFamily:         C2LOP.P\tNumber of images: 146\n",
      "Label: 8\tFamily:  Dialplatform.B\tNumber of images: 177\n",
      "Label: 9\tFamily:       Dontovo.A\tNumber of images: 162\n",
      "Label:10\tFamily:        Fakerean\tNumber of images: 381\n",
      "Label:11\tFamily:   Instantaccess\tNumber of images: 431\n",
      "Label:12\tFamily:      Lolyda.AA1\tNumber of images: 213\n",
      "Label:13\tFamily:      Lolyda.AA2\tNumber of images: 184\n",
      "Label:14\tFamily:      Lolyda.AA3\tNumber of images: 123\n",
      "Label:15\tFamily:       Lolyda.AT\tNumber of images: 159\n",
      "Label:16\tFamily:     Malex.gen!J\tNumber of images: 136\n",
      "Label:17\tFamily:   Obfuscator.AD\tNumber of images: 142\n",
      "Label:18\tFamily:        Rbot!gen\tNumber of images: 158\n",
      "Label:19\tFamily:      Skintrim.N\tNumber of images: 80\n",
      "Label:20\tFamily:   Swizzor.gen!E\tNumber of images: 128\n",
      "Label:21\tFamily:   Swizzor.gen!I\tNumber of images: 132\n",
      "Label:22\tFamily:           VB.AT\tNumber of images: 408\n",
      "Label:23\tFamily:      Wintrim.BX\tNumber of images: 97\n",
      "Label:24\tFamily:         Yuner.A\tNumber of images: 800\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n",
      "Images processed: 9339\n"
     ]
    }
   ],
   "source": [
    "width, height, channels = (224, 224, 3) #image input shape\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "paths_list = []\n",
    "print(\"Processing images...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in glob.glob(list_fams[i]+'/*.png'):\n",
    "        paths_list.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = load_img(img_file, target_size=(224, 224))\n",
    "        x = img_to_array(img) #image to array\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9339, 224, 224, 3), (9339,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., 25., 25., 25.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG's  22  layers are not added to the layer\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "vgg = Sequential()\n",
    "vgg.add(Conv2D(3, (3, 3), padding='same', input_shape=(224, 224, 3)))\n",
    "vgg.add(Activation('relu'))\n",
    "\n",
    "_vgg = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "counter=0\n",
    "for layer in _vgg.layers:\n",
    "    layer.trainable = False\n",
    "    counter+=1\n",
    "\n",
    "print(\"VGG's \", counter , \" layers are not added to the layer\")\n",
    "vgg.add(_vgg)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.add(Flatten())\n",
    "\n",
    "vgg.add(Dense(4096,activation='relu'))\n",
    "vgg.add(Dense(4096,activation='relu'))\n",
    "vgg.add(Dense(128,activation=\"relu\"))\n",
    "\n",
    "vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 3)       84        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, None, None, 512)   20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,094,740\n",
      "Trainable params: 120,070,356\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 40min 7s, sys: 40min 50s, total: 3h 20min 57s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#extracting features\n",
    "features = vgg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.4335973 ,  1.1801233 ,  0.        ,  0.        ,\n",
       "        1.1441605 ,  0.        ,  1.2447736 ,  3.5791337 ,  1.8121624 ,\n",
       "        0.54464364,  0.        ,  8.859711  ,  3.2367206 ,  6.1709566 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  5.1614804 ,  0.        ,  0.        ,  1.4694793 ,\n",
       "        0.        ,  2.6160254 ,  3.6512933 ,  0.        ,  7.204133  ,\n",
       "        7.839667  ,  4.5557547 ,  0.        ,  0.        , 10.083174  ,\n",
       "       10.682317  ,  4.1361246 ,  0.        ,  7.5855184 , 10.57449   ,\n",
       "        0.        ,  0.        ,  6.7147326 ,  2.1950986 ,  2.684094  ,\n",
       "        2.5829802 ,  0.07743825,  0.        ,  0.        ,  5.178196  ,\n",
       "        4.047161  ,  1.8789101 ,  1.3213978 ,  3.154185  ,  3.8703866 ,\n",
       "        1.9163661 ,  0.        ,  7.042651  ,  0.        ,  5.5225854 ,\n",
       "        7.4342804 ,  2.0578535 ,  2.5033967 ,  0.        ,  7.065427  ,\n",
       "        0.5944731 ,  0.7172077 ,  5.6707273 ,  0.        ,  0.        ,\n",
       "        3.8087788 ,  4.73853   ,  0.98327327,  0.        ,  3.6470091 ,\n",
       "        1.6027366 ,  6.504379  ,  1.5389861 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.33772266,\n",
       "        3.389009  ,  1.7235441 ,  3.384654  ,  5.8762455 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.9633934 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.38021755,  5.045852  ,  0.        ,\n",
       "        3.68048   ,  7.2143555 ,  0.        ,  0.5059769 ,  8.910061  ,\n",
       "        0.        ,  0.20200592,  0.        ,  0.        ,  5.9206586 ,\n",
       "        8.123112  ,  0.        ,  0.        ,  5.473859  ,  0.        ,\n",
       "        6.8621216 ,  1.9282471 ,  0.        ,  4.776305  ,  4.158133  ,\n",
       "        0.        ,  4.7665253 ,  0.        ,  0.        ,  2.5469954 ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/sanjeev/DL_Exp_Kajal/Finetune_stack_features/MalImg/vgg16_feat_malimg_128.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.load(\"/home/sanjeev/DL_Exp_Kajal/Finetune_stack_features/MalImg/vgg16_feat_malimg_128.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 24., 24., 24.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "(8405, 128) (8405,)\n",
      "(934, 128) (934,)\n",
      "Training Accuracy:  98.12\n",
      "Testing Accuracy:  97.109\n",
      "Model Accuracy for cross validation: 97.21\n",
      "Precision: 97\n",
      "Recall: 97\n",
      "F1_Score: 97\n",
      "*---------------------------*\n",
      "SVC(random_state=31)\n",
      "(8405, 128) (8405,)\n",
      "(934, 128) (934,)\n",
      "Training Accuracy:  98.977\n",
      "Testing Accuracy:  97.859\n",
      "Model Accuracy for cross validation: 98.03\n",
      "Precision: 98\n",
      "Recall: 98\n",
      "F1_Score: 98\n",
      "*---------------------------*\n",
      "RandomForestClassifier(random_state=31)\n",
      "(8405, 128) (8405,)\n",
      "(934, 128) (934,)\n",
      "Training Accuracy:  100.0\n",
      "Testing Accuracy:  96.788\n",
      "Model Accuracy for cross validation: 97.07\n",
      "Precision: 97\n",
      "Recall: 97\n",
      "F1_Score: 97\n",
      "*---------------------------*\n",
      "MLPClassifier(max_iter=500, random_state=31)\n",
      "(8405, 128) (8405,)\n",
      "(934, 128) (934,)\n",
      "Training Accuracy:  100.0\n",
      "Testing Accuracy:  97.752\n",
      "Model Accuracy for cross validation: 97.85\n",
      "Precision: 98\n",
      "Recall: 98\n",
      "F1_Score: 98\n",
      "*---------------------------*\n",
      "ExtraTreeClassifier(random_state=31)\n",
      "(8405, 128) (8405,)\n",
      "(934, 128) (934,)\n",
      "Training Accuracy:  100.0\n",
      "Testing Accuracy:  85.653\n",
      "Model Accuracy for cross validation: 82.36\n",
      "Precision: 86\n",
      "Recall: 86\n",
      "F1_Score: 86\n",
      "*---------------------------*\n",
      "GaussianNB()\n",
      "(8405, 128) (8405,)\n",
      "(934, 128) (934,)\n",
      "Training Accuracy:  91.695\n",
      "Testing Accuracy:  91.435\n",
      "Model Accuracy for cross validation: 88.87\n",
      "Precision: 91\n",
      "Recall: 91\n",
      "F1_Score: 91\n",
      "*---------------------------*\n",
      "[97.109, 97.859, 96.788, 97.752, 85.653, 91.435, 97, 98, 97, 98, 86, 91, 97, 98, 97, 98, 86, 91, 97, 98, 97, 98, 86, 91, 97.21, 98.03, 97.07, 97.85, 82.36, 88.87]\n"
     ]
    }
   ],
   "source": [
    "#classification model creation using different classifiers\n",
    "def classify(model, x, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=31)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "\n",
    "    model.fit(X_train, y_train)   \n",
    "    print(\"Training Accuracy: \", round(model.score(X_train, y_train)*100,3))\n",
    "    print(\"Testing Accuracy: \", round(model.score(X_test, y_test)*100,3))\n",
    "    acc = round(model.score(X_test, y_test)*100,3)\n",
    "    \n",
    "    score = cross_val_score(model, x, y, cv=5)\n",
    "    print(\"Model Accuracy for cross validation:\", round(np.mean(score)*100, 2))\n",
    "    cv = round(np.mean(score)*100, 2)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    print('Precision:', int(round(precision_recall_fscore_support(y_test, pred, average='micro')[0]*100, 0)))\n",
    "    print('Recall:', int(round(precision_recall_fscore_support(y_test, pred, average='micro')[1]*100, 0)))\n",
    "    print('F1_Score:', int(round(precision_recall_fscore_support(y_test, pred, average='micro')[2]*100, 0)))\n",
    "    ls = precision_recall_fscore_support(y_test, pred, average='micro')\n",
    "    pre, rec, f1 = int(round(ls[0]*100, 0)), int(round(ls[1]*100, 0)), int(round(ls[2]*100, 0))\n",
    "    print('*---------------------------*')\n",
    "    return [acc, pre, rec, f1, cv]\n",
    "\n",
    "classifiers = [KNeighborsClassifier(),\n",
    "               SVC(random_state=31),\n",
    "               RandomForestClassifier(random_state=31),\n",
    "               MLPClassifier(random_state=31, max_iter=500),\n",
    "               ExtraTreeClassifier(random_state=31),\n",
    "               GaussianNB()]\n",
    "\n",
    "ls_acc, ls_pre, ls_rec, ls_f1, ls_cv = [],[],[],[],[]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier)\n",
    "    values = classify(classifier, feat, y)       \n",
    "    \n",
    "    ls_acc.append(values[0])\n",
    "    ls_pre.append(values[1])\n",
    "    ls_rec.append(values[2])\n",
    "    ls_f1.append(values[3])\n",
    "    ls_cv.append(values[4])\n",
    "    \n",
    "print([*ls_acc, *ls_pre, *ls_rec, *ls_f1, *ls_cv])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
