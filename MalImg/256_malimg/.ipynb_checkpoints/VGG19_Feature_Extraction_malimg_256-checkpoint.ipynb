{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#importing keras libraries\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Dense, Activation ,Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "#importing sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory path for full dataset\n",
    "imagedir =\"/home/sanjeev/DL_POC/MlaImg_Data/Malimg_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tFamily:       Adialer.C\tNumber of images: 122\n",
      "Label: 1\tFamily:       Agent.FYI\tNumber of images: 116\n",
      "Label: 2\tFamily:       Allaple.A\tNumber of images: 2949\n",
      "Label: 3\tFamily:       Allaple.L\tNumber of images: 1591\n",
      "Label: 4\tFamily:   Alueron.gen!J\tNumber of images: 198\n",
      "Label: 5\tFamily:       Autorun.K\tNumber of images: 106\n",
      "Label: 6\tFamily:     C2LOP.gen!g\tNumber of images: 200\n",
      "Label: 7\tFamily:         C2LOP.P\tNumber of images: 146\n",
      "Label: 8\tFamily:  Dialplatform.B\tNumber of images: 177\n",
      "Label: 9\tFamily:       Dontovo.A\tNumber of images: 162\n",
      "Label:10\tFamily:        Fakerean\tNumber of images: 381\n",
      "Label:11\tFamily:   Instantaccess\tNumber of images: 431\n",
      "Label:12\tFamily:      Lolyda.AA1\tNumber of images: 213\n",
      "Label:13\tFamily:      Lolyda.AA2\tNumber of images: 184\n",
      "Label:14\tFamily:      Lolyda.AA3\tNumber of images: 123\n",
      "Label:15\tFamily:       Lolyda.AT\tNumber of images: 159\n",
      "Label:16\tFamily:     Malex.gen!J\tNumber of images: 136\n",
      "Label:17\tFamily:   Obfuscator.AD\tNumber of images: 142\n",
      "Label:18\tFamily:        Rbot!gen\tNumber of images: 158\n",
      "Label:19\tFamily:      Skintrim.N\tNumber of images: 80\n",
      "Label:20\tFamily:   Swizzor.gen!E\tNumber of images: 128\n",
      "Label:21\tFamily:   Swizzor.gen!I\tNumber of images: 132\n",
      "Label:22\tFamily:           VB.AT\tNumber of images: 408\n",
      "Label:23\tFamily:      Wintrim.BX\tNumber of images: 97\n",
      "Label:24\tFamily:         Yuner.A\tNumber of images: 800\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n",
      "Images processed: 9339\n"
     ]
    }
   ],
   "source": [
    "width, height, channels = (224, 224, 3) #image input shape\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "paths_list = []\n",
    "print(\"Processing images...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in glob.glob(list_fams[i]+'/*.png'):\n",
    "        paths_list.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = load_img(img_file, target_size=(224, 224))\n",
    "        x = img_to_array(img) #image to array\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9339, 224, 224, 3), (9339,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 24., 24., 24.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG's  22  layers are not added to the layer\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "vgg = Sequential()\n",
    "vgg.add(Conv2D(3, (3, 3), padding='same', input_shape=(224, 224, 3)))\n",
    "vgg.add(Activation('relu'))\n",
    "\n",
    "_vgg = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "counter=0\n",
    "for layer in _vgg.layers:\n",
    "    layer.trainable = False\n",
    "    counter+=1\n",
    "\n",
    "print(\"VGG's \", counter , \" layers are not added to the layer\")\n",
    "vgg.add(_vgg)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.add(Flatten())\n",
    "\n",
    "vgg.add(Dense(4096,activation='relu'))\n",
    "vgg.add(Dense(256,activation=\"relu\"))\n",
    "\n",
    "vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 3)       84        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, None, None, 512)   20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,837,844\n",
      "Trainable params: 103,813,460\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 37min 50s, sys: 35min 18s, total: 3h 13min 9s\n",
      "Wall time: 9min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#extracting features\n",
    "features = vgg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.80790615,\n",
       "       11.850269  ,  0.        ,  1.5325544 ,  2.2890177 ,  0.        ,\n",
       "        6.137166  ,  0.        , 12.27322   , 10.042033  ,  0.        ,\n",
       "        0.53379   ,  0.        ,  0.        ,  0.        ,  9.557861  ,\n",
       "        6.9684772 ,  3.1154299 ,  0.35984507,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , 10.722442  ,  3.845831  ,  1.8056273 ,\n",
       "        5.3761926 ,  3.0196748 ,  0.        ,  0.        ,  5.3999133 ,\n",
       "       12.984273  ,  3.3744318 ,  0.        ,  3.3476558 ,  0.        ,\n",
       "        3.6738856 ,  8.860779  ,  0.        ,  4.3874216 ,  0.        ,\n",
       "        0.32158172,  0.        ,  0.        ,  0.91974485,  2.64669   ,\n",
       "        0.        ,  0.        , 14.7239065 ,  1.7488075 ,  0.        ,\n",
       "        0.        ,  0.5197401 ,  2.8440638 ,  0.7771004 ,  5.7082386 ,\n",
       "        0.        ,  1.0909736 ,  2.820015  ,  0.        , 17.19569   ,\n",
       "        0.        ,  3.8072703 ,  2.5053043 ,  0.        ,  6.0279617 ,\n",
       "        1.4624298 ,  7.1291485 ,  7.275134  ,  3.4698749 ,  0.        ,\n",
       "        0.        ,  0.        ,  5.0664573 ,  0.14497662,  3.5649877 ,\n",
       "        0.        ,  0.        ,  6.722587  , 15.80493   ,  7.2941637 ,\n",
       "        0.        ,  5.015394  ,  2.9752316 ,  6.3758717 ,  0.        ,\n",
       "        0.        ,  8.866752  ,  0.        ,  0.        ,  0.        ,\n",
       "        3.2934864 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  5.6189632 ,  5.278713  ,\n",
       "        2.6430888 ,  8.134773  ,  0.        ,  5.9761486 , 12.138659  ,\n",
       "        0.87454295,  0.        ,  0.        ,  0.        ,  1.1860423 ,\n",
       "        0.43948025,  0.        ,  8.280837  ,  0.        ,  0.48073196,\n",
       "        0.        ,  3.7421231 ,  3.867887  ,  0.7209476 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  6.585045  ,\n",
       "       14.898689  ,  0.        ,  0.3307454 ,  3.190206  ,  0.        ,\n",
       "        0.        ,  0.        ,  5.7653785 ,  1.2554234 ,  6.203348  ,\n",
       "        0.        ,  0.        ,  4.690638  ,  0.        ,  8.51784   ,\n",
       "        0.        ,  0.        ,  5.1380796 ,  0.        ,  8.882793  ,\n",
       "        0.        ,  1.5073874 ,  0.        ,  3.3057678 ,  0.        ,\n",
       "        8.370933  ,  0.        , 12.1048565 ,  1.3000768 ,  0.        ,\n",
       "        0.        ,  5.4837284 ,  0.22607684,  0.        ,  0.        ,\n",
       "        1.8516593 ,  3.8149688 ,  5.993249  ,  1.7234114 ,  0.        ,\n",
       "        9.622482  , 10.7269745 ,  5.7449055 ,  1.3174311 ,  2.6011982 ,\n",
       "        6.854595  ,  6.5876265 ,  2.8608963 ,  0.        , 17.135014  ,\n",
       "       17.243162  ,  4.158293  ,  0.        ,  4.7734156 ,  0.        ,\n",
       "        0.9934606 ,  8.09163   ,  6.8272305 ,  0.        ,  4.930467  ,\n",
       "        0.        ,  7.7090836 ,  1.6733341 ,  0.        ,  1.2998028 ,\n",
       "        6.2638063 ,  0.9213412 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  4.3190756 ,  1.962273  ,\n",
       "        0.        ,  5.007477  ,  0.        ,  1.8863074 ,  5.9026623 ,\n",
       "        0.        ,  1.0556831 ,  7.161589  ,  1.5024221 ,  0.        ,\n",
       "        7.4940104 , 10.927333  ,  0.        ,  0.        ,  0.53643763,\n",
       "        0.        ,  0.        ,  0.        ,  2.800464  ,  5.356804  ,\n",
       "        7.6886306 ,  7.753229  ,  0.9477959 ,  0.        ,  3.8754246 ,\n",
       "        0.40911388,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        3.7773461 ,  6.078862  ,  3.2629151 ,  0.        ,  6.6303816 ,\n",
       "        5.631407  ,  0.        ,  0.        ,  7.825596  ,  0.        ,\n",
       "        0.        ,  5.4102325 ,  0.        ,  7.498767  ,  0.        ,\n",
       "        0.        ,  0.        ,  0.91885906,  0.        ,  0.3381033 ,\n",
       "        1.4003713 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/sanjeev/DL_Exp_Kajal/Finetune_stack_features/MalImg/vgg19_feat_malimg_256.npy', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.load(\"/home/sanjeev/DL_Exp_Kajal/Finetune_stack_features/MalImg/vgg19_feat_malimg_256.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 24., 24., 24.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "(8405, 256) (8405,)\n",
      "(934, 256) (934,)\n",
      "Training Accuracy:  98.12\n",
      "Testing Accuracy:  97.43\n",
      "Model Accuracy for cross validation: 97.44\n",
      "Precision: 97\n",
      "Recall: 97\n",
      "F1_Score: 97\n",
      "*---------------------------*\n",
      "SVC(random_state=31)\n",
      "(8405, 256) (8405,)\n",
      "(934, 256) (934,)\n",
      "Training Accuracy:  99.143\n",
      "Testing Accuracy:  98.501\n",
      "Model Accuracy for cross validation: 98.17\n",
      "Precision: 99\n",
      "Recall: 99\n",
      "F1_Score: 99\n",
      "*---------------------------*\n",
      "RandomForestClassifier(random_state=31)\n",
      "(8405, 256) (8405,)\n",
      "(934, 256) (934,)\n",
      "Training Accuracy:  100.0\n",
      "Testing Accuracy:  97.323\n",
      "Model Accuracy for cross validation: 96.7\n",
      "Precision: 97\n",
      "Recall: 97\n",
      "F1_Score: 97\n",
      "*---------------------------*\n",
      "MLPClassifier(max_iter=500, random_state=31)\n",
      "(8405, 256) (8405,)\n",
      "(934, 256) (934,)\n",
      "Training Accuracy:  100.0\n",
      "Testing Accuracy:  98.608\n",
      "Model Accuracy for cross validation: 97.72\n",
      "Precision: 99\n",
      "Recall: 99\n",
      "F1_Score: 99\n",
      "*---------------------------*\n",
      "ExtraTreeClassifier(random_state=31)\n",
      "(8405, 256) (8405,)\n",
      "(934, 256) (934,)\n",
      "Training Accuracy:  100.0\n",
      "Testing Accuracy:  85.546\n",
      "Model Accuracy for cross validation: 84.79\n",
      "Precision: 86\n",
      "Recall: 86\n",
      "F1_Score: 86\n",
      "*---------------------------*\n",
      "GaussianNB()\n",
      "(8405, 256) (8405,)\n",
      "(934, 256) (934,)\n",
      "Training Accuracy:  91.743\n",
      "Testing Accuracy:  88.33\n",
      "Model Accuracy for cross validation: 89.6\n",
      "Precision: 88\n",
      "Recall: 88\n",
      "F1_Score: 88\n",
      "*---------------------------*\n",
      "[97.43, 98.501, 97.323, 98.608, 85.546, 88.33, 97, 99, 97, 99, 86, 88, 97, 99, 97, 99, 86, 88, 97, 99, 97, 99, 86, 88, 97.44, 98.17, 96.7, 97.72, 84.79, 89.6]\n"
     ]
    }
   ],
   "source": [
    "#classification model creation using different classifiers\n",
    "def classify(model, x, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=31)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "\n",
    "    model.fit(X_train, y_train)   \n",
    "    print(\"Training Accuracy: \", round(model.score(X_train, y_train)*100,3))\n",
    "    print(\"Testing Accuracy: \", round(model.score(X_test, y_test)*100,3))\n",
    "    acc = round(model.score(X_test, y_test)*100,3)\n",
    "    \n",
    "    score = cross_val_score(model, x, y, cv=5)\n",
    "    print(\"Model Accuracy for cross validation:\", round(np.mean(score)*100, 2))\n",
    "    cv = round(np.mean(score)*100, 2)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    print('Precision:', int(round(precision_recall_fscore_support(y_test, pred, average='micro')[0]*100, 0)))\n",
    "    print('Recall:', int(round(precision_recall_fscore_support(y_test, pred, average='micro')[1]*100, 0)))\n",
    "    print('F1_Score:', int(round(precision_recall_fscore_support(y_test, pred, average='micro')[2]*100, 0)))\n",
    "    ls = precision_recall_fscore_support(y_test, pred, average='micro')\n",
    "    pre, rec, f1 = int(round(ls[0]*100, 0)), int(round(ls[1]*100, 0)), int(round(ls[2]*100, 0))\n",
    "    print('*---------------------------*')\n",
    "    return [acc, pre, rec, f1, cv]\n",
    "\n",
    "classifiers = [KNeighborsClassifier(),\n",
    "               SVC(random_state=31),\n",
    "               RandomForestClassifier(random_state=31),\n",
    "               MLPClassifier(random_state=31, max_iter=500),\n",
    "               ExtraTreeClassifier(random_state=31),\n",
    "               GaussianNB()]\n",
    "\n",
    "ls_acc, ls_pre, ls_rec, ls_f1, ls_cv = [],[],[],[],[]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier)\n",
    "    values = classify(classifier, feat, y)       \n",
    "    \n",
    "    ls_acc.append(values[0])\n",
    "    ls_pre.append(values[1])\n",
    "    ls_rec.append(values[2])\n",
    "    ls_f1.append(values[3])\n",
    "    ls_cv.append(values[4])\n",
    "    \n",
    "print([*ls_acc, *ls_pre, *ls_rec, *ls_f1, *ls_cv])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
